# -*- coding: utf-8 -*-
"""Predictive analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WWrvL56E5QBQLY3sK_SLGkdgAnVr6cQn

Setup
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.preprocessing import RobustScaler
import math

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files
uploaded = files.upload()

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/mock_kaggle.csv')
print("Dataset loaded successfully!")
print(f"Dataset shape: {df.shape}")
print("\nFirst few rows:")
print(df.head())

"""Data Loading and Preparation"""

df = pd.read_csv('mock_kaggle.csv')
df['data'] = pd.to_datetime(df['data'])
df = df.rename(columns={
    'data': 'date',
    'venda': 'sales',
    'estoque': 'inventory',
    'preco': 'price'
})

date_range = pd.date_range(start=df['date'].min(), end=df['date'].max(), freq='D')
df_complete = df.set_index('date').reindex(date_range).reset_index()
df_complete = df_complete.rename(columns={'index': 'date'})
df_complete['sales'] = df_complete['sales'].fillna(method='ffill')
df_complete['inventory'] = df_complete['inventory'].fillna(method='ffill')
df_complete['price'] = df_complete['price'].fillna(method='ffill')
df_complete = df_complete.dropna()

"""Feature Engineering


"""

def create_features(df):
    df_featured = df.copy()
    df_featured['day_of_week'] = df_featured['date'].dt.dayofweek
    df_featured['day_of_month'] = df_featured['date'].dt.day
    df_featured['week_of_year'] = df_featured['date'].dt.isocalendar().week
    df_featured['month'] = df_featured['date'].dt.month
    df_featured['quarter'] = df_featured['date'].dt.quarter
    df_featured['year'] = df_featured['date'].dt.year
    df_featured['sin_day_of_year'] = np.sin(2 * np.pi * df_featured['date'].dt.dayofyear / 365)
    df_featured['cos_day_of_year'] = np.cos(2 * np.pi * df_featured['date'].dt.dayofyear / 365)
    df_featured['sales_lag_7'] = df_featured['sales'].shift(7)
    df_featured['sales_lag_30'] = df_featured['sales'].shift(30)
    df_featured['sales_rolling_mean_7'] = df_featured['sales'].rolling(window=7, min_periods=1).mean()
    df_featured['sales_rolling_std_7'] = df_featured['sales'].rolling(window=7, min_periods=1).std()
    df_featured['sales_rolling_mean_30'] = df_featured['sales'].rolling(window=30, min_periods=1).mean()
    df_featured['price_change'] = df_featured['price'].pct_change()
    df_featured['price_rolling_mean_7'] = df_featured['price'].rolling(window=7, min_periods=1).mean()
    df_featured['inventory_change'] = df_featured['inventory'].pct_change()
    df_featured['inventory_rolling_mean_7'] = df_featured['inventory'].rolling(window=7, min_periods=1).mean()
    df_featured['sales_inventory_ratio'] = df_featured['sales'] / (df_featured['inventory'] + 1)
    df_featured['is_weekend'] = (df_featured['day_of_week'] >= 5).astype(int)
    df_featured = df_featured.dropna()
    return df_featured

df_engineered = create_features(df_complete)

"""Data Cleaning and Preprocessing"""

features = [col for col in df_engineered.columns if col not in ['date', 'sales']]
X = df_engineered[features]
y = df_engineered['sales']

X_clean = X.copy()
y_clean = y.copy()
X_clean = X_clean.replace([np.inf, -np.inf], np.nan)
nan_columns = X_clean.columns[X_clean.isna().any()].tolist()
for col in nan_columns:
    X_clean[col] = X_clean[col].fillna(X_clean[col].median())
for col in X_clean.columns:
    q99 = X_clean[col].quantile(0.99)
    q1 = X_clean[col].quantile(0.01)
    upper_bound = q99 * 5
    lower_bound = q1 * 5 if q1 > 0 else q1
    X_clean[col] = np.clip(X_clean[col], lower_bound, upper_bound)

split_date = df_engineered['date'].max() - timedelta(days=90)
X_train = X_clean[df_engineered['date'] <= split_date]
X_test = X_clean[df_engineered['date'] > split_date]
y_train = y_clean[df_engineered['date'] <= split_date]
y_test = y_clean[df_engineered['date'] > split_date]

"""Data Scaling"""

robust_scaler = RobustScaler()
X_train_scaled = robust_scaler.fit_transform(X_train)
X_test_scaled = robust_scaler.transform(X_test)
X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=features, index=X_train.index)
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=features, index=X_test.index)

""" Model Training"""

xgb_model = XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=6,
    random_state=42
)
xgb_model.fit(X_train_scaled_df, y_train)

rf_model = RandomForestRegressor(
    n_estimators=100,
    random_state=42,
    n_jobs=-1
)
rf_model.fit(X_train_scaled_df, y_train)

""" Model Evaluation"""

xgb_pred = xgb_model.predict(X_test_scaled_df)
rf_pred = rf_model.predict(X_test_scaled_df)

def calculate_metrics(y_true, y_pred, model_name):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = math.sqrt(mse)
    mape = np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1))) * 100
    print(f"{model_name} Performance:")
    print(f"MAE: {mae:.2f}")
    print(f"RMSE: {rmse:.2f}")
    print(f"MAPE: {mape:.2f}%")
    return mae, rmse, mape

xgb_mae, xgb_rmse, xgb_mape = calculate_metrics(y_test, xgb_pred, "XGBoost")
rf_mae, rf_rmse, rf_mape = calculate_metrics(y_test, rf_pred, "Random Forest")

test_dates = df_engineered[df_engineered['date'] > split_date]['date']
plt.figure(figsize=(15, 8))
plt.plot(test_dates, y_test.values, label='Actual Sales', linewidth=2, color='black')
plt.plot(test_dates, xgb_pred, label='XGBoost Prediction', alpha=0.8, linestyle='--')
plt.plot(test_dates, rf_pred, label='Random Forest Prediction', alpha=0.8, linestyle='--')
plt.title('Model Predictions vs Actual Sales')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.legend()
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

""" Prophet Model"""

pip install prophet --upgrade

from prophet import Prophet

prophet_df = df_complete[['date', 'sales']].rename(columns={'date': 'ds', 'sales': 'y'})
prophet_train = prophet_df[prophet_df['ds'] <= split_date]
prophet_test = prophet_df[prophet_df['ds'] > split_date]

prophet_model = Prophet(
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=False,
    changepoint_prior_scale=0.05
)
prophet_model.fit(prophet_train)
future = prophet_model.make_future_dataframe(periods=len(prophet_test), include_history=False)
forecast = prophet_model.predict(future)

prophet_pred = forecast['yhat'].values
prophet_actual = prophet_test['y'].values
prophet_mae, prophet_rmse, prophet_mape = calculate_metrics(prophet_actual, prophet_pred, "Prophet")

fig1 = prophet_model.plot(forecast)
plt.title('Prophet Sales Forecast')
plt.show()

fig2 = prophet_model.plot_components(forecast)
plt.show()

"""Future Predictions"""

last_date = df_engineered['date'].max()
future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=90, freq='D')
future_features_list = []

for date in future_dates:
    future_row = {}
    future_row['day_of_week'] = date.dayofweek
    future_row['day_of_month'] = date.day
    future_row['week_of_year'] = date.isocalendar().week
    future_row['month'] = date.month
    future_row['quarter'] = date.quarter
    future_row['year'] = date.year
    future_row['sin_day_of_year'] = np.sin(2 * np.pi * date.dayofyear / 365)
    future_row['cos_day_of_year'] = np.cos(2 * np.pi * date.dayofyear / 365)
    future_row['is_weekend'] = 1 if date.dayofweek >= 5 else 0

    last_values = df_engineered.iloc[-1]
    for feature in features:
        if feature in ['inventory', 'price', 'sales_lag_7', 'sales_lag_30',
                      'sales_rolling_mean_7', 'sales_rolling_std_7', 'sales_rolling_mean_30',
                      'price_change', 'price_rolling_mean_7', 'inventory_change',
                      'inventory_rolling_mean_7', 'sales_inventory_ratio']:
            future_row[feature] = last_values[feature]
        else:
            future_row[feature] = last_values[feature]

    future_features_list.append(future_row)

future_features_df = pd.DataFrame(future_features_list)
future_features_clean = future_features_df[features].replace([np.inf, -np.inf], np.nan)
for col in future_features_clean.columns:
    future_features_clean[col] = future_features_clean[col].fillna(future_features_clean[col].median())
future_features_scaled = robust_scaler.transform(future_features_clean)
future_predictions = xgb_model.predict(future_features_scaled)

future_forecast = pd.DataFrame({
    'date': future_dates,
    'predicted_sales': future_predictions
})

plt.figure(figsize=(15, 8))
historical_recent = df_complete[df_complete['date'] >= (last_date - timedelta(days=180))]
plt.plot(historical_recent['date'], historical_recent['sales'], label='Historical Sales', color='blue', linewidth=2)
plt.plot(future_forecast['date'], future_forecast['predicted_sales'], label='Predicted Sales', color='red', linestyle='--', linewidth=2)
plt.title('Sales Forecast: Historical and Future Predictions')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.legend()
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

"""Power BI Data Export"""

def prepare_powerbi_data(historical_df, forecast_df, model_performance):
    historical_export = historical_df[['date', 'sales', 'inventory', 'price']].copy()
    forecast_export = forecast_df.copy()
    forecast_export['data_type'] = 'Forecast'
    forecast_export['inventory'] = None
    forecast_export['price'] = None
    historical_export['data_type'] = 'Historical'
    combined_data = pd.concat([
        historical_export.rename(columns={'sales': 'value'}),
        forecast_export[['date', 'predicted_sales', 'data_type', 'inventory', 'price']].rename(columns={'predicted_sales': 'value'})
    ], ignore_index=True)
    monthly_data = combined_data.copy()
    monthly_data['year_month'] = monthly_data['date'].dt.to_period('M')
    monthly_agg = monthly_data.groupby(['year_month', 'data_type']).agg({
        'value': ['sum', 'mean', 'std'],
        'inventory': 'mean',
        'price': 'mean'
    }).reset_index()
    monthly_agg.columns = ['year_month', 'data_type', 'total_sales', 'avg_sales', 'std_sales', 'avg_inventory', 'avg_price']
    performance_data = pd.DataFrame(model_performance).T.reset_index().rename(
        columns={'index': 'model', 0: 'MAE', 1: 'RMSE', 2: 'MAPE'})
    return combined_data, monthly_agg, performance_data

model_performance = {
    'XGBoost': [xgb_mae, xgb_rmse, xgb_mape],
    'Random Forest': [rf_mae, rf_rmse, rf_mape],
    'Prophet': [prophet_mae, prophet_rmse, prophet_mape]
}

daily_data, monthly_data, performance_data = prepare_powerbi_data(df_complete, future_forecast, model_performance)

daily_data.to_csv('sales_forecast_daily_data.csv', index=False)
monthly_data.to_csv('sales_forecast_monthly_data.csv', index=False)
performance_data.to_csv('model_performance_data.csv', index=False)
future_forecast.to_csv('future_forecast_detailed.csv', index=False)

from google.colab import files
files.download('sales_forecast_daily_data.csv')
files.download('sales_forecast_monthly_data.csv')
files.download('model_performance_data.csv')
files.download('future_forecast_detailed.csv')

"""Business Insights"""

def generate_business_insights(historical_df, forecast_df):
    insights = []
    recent_avg = historical_df[historical_df['date'] >= (historical_df['date'].max() - timedelta(days=30))]['sales'].mean()
    future_avg = forecast_df['predicted_sales'].mean()
    growth = ((future_avg - recent_avg) / recent_avg) * 100 if recent_avg > 0 else 0
    if growth > 0:
        insights.append(f"Positive Trend: Predicted growth of {growth:.1f}% in average daily sales")
    else:
        insights.append(f"Caution: Predicted decrease of {abs(growth):.1f}% in average daily sales")
    monthly_avg = historical_df.groupby(historical_df['date'].dt.month)['sales'].mean()
    best_month = monthly_avg.idxmax()
    worst_month = monthly_avg.idxmin()
    insights.append(f"Seasonality: Strongest sales in month {best_month}, weakest in month {worst_month}")
    price_corr = historical_df['price'].corr(historical_df['sales'])
    if price_corr < -0.3:
        insights.append(f"Price Sensitivity: Strong negative correlation ({price_corr:.2f}) between price and sales")
    elif price_corr > 0.3:
        insights.append(f"Premium Effect: Positive correlation ({price_corr:.2f}) suggesting premium positioning")
    inventory_turnover = historical_df['sales'].sum() / historical_df['inventory'].mean()
    insights.append(f"Inventory Turnover: Overall turnover ratio of {inventory_turnover:.2f}")
    total_forecast = forecast_df['predicted_sales'].sum()
    peak_day = forecast_df.loc[forecast_df['predicted_sales'].idxmax()]
    insights.append(f"Forecast: Total predicted sales of {total_forecast:,.0f} over next 90 days")
    insights.append(f"Peak Day: Highest sales expected on {peak_day['date'].strftime('%Y-%m-%d')} ({peak_day['predicted_sales']:.0f} units)")
    return insights

business_insights = generate_business_insights(df_complete, future_forecast)
print("BUSINESS INSIGHTS AND RECOMMENDATIONS")
for i, insight in enumerate(business_insights, 1):
    print(f"{i}. {insight}")

recommendations = [
    "Inventory Optimization: Align stock levels with predicted demand patterns",
    "Pricing Strategy: Test optimal price points based on price-sensitivity analysis",
    "Demand Planning: Use forecasts for production and procurement planning",
    "Marketing Focus: Target promotions during predicted low-sales periods",
    "Model Monitoring: Continuously validate predictions against actual sales",
    "Trend Analysis: Monitor for emerging patterns beyond seasonal trends"
]

print("RECOMMENDED ACTIONS")
for rec in recommendations:
    print(f"â€¢ {rec}")